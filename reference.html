<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="" />
    <meta name="keywords" content="" />
    <link rel="icon" href="assets/images/favicon.png" sizes="35x35" type="image/png">
    <title>JSTSP</title>

    <link rel="stylesheet" href="assets/css/all.min.css">
    <link rel="stylesheet" href="assets/css/flaticon.css">
    <link rel="stylesheet" href="assets/css/animate.min.css">
    <link rel="stylesheet" href="assets/css/bootstrap.min.css">
    <link rel="stylesheet" href="assets/css/jquery.fancybox.min.css">
    <link rel="stylesheet" href="assets/css/perfect-scrollbar.css">
    <!--<link rel="stylesheet" href="assets/css/slick.css">-->
    <link rel="stylesheet" href="assets/css/style.css">
    <link rel="stylesheet" href="assets/css/responsive.css">
    <link rel="stylesheet" href="assets/css/color.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    <link rel='stylesheet' href='https://cdn-uicons.flaticon.com/2.3.0/uicons-thin-rounded/css/uicons-thin-rounded.css'>
    <link rel='stylesheet'
        href='https://cdn-uicons.flaticon.com/2.3.0/uicons-regular-rounded/css/uicons-regular-rounded.css'>
    <link rel='stylesheet' href='https://cdn-uicons.flaticon.com/2.3.0/uicons-bold-rounded/css/uicons-bold-rounded.css'>
    <link rel='stylesheet'
        href='https://cdn-uicons.flaticon.com/2.3.0/uicons-solid-straight/css/uicons-solid-straight.css'>
    <link rel='stylesheet'
        href='https://cdn-uicons.flaticon.com/2.3.0/uicons-regular-rounded/css/uicons-regular-rounded.css'>
    <link rel='stylesheet'
        href='https://cdn-uicons.flaticon.com/2.3.0/uicons-solid-rounded/css/uicons-solid-rounded.css'>
</head>

<body>
    <main>
        <header class="stick style1 w-100">
            <div class="container">
                <div class="logo-menu-wrap w-100 d-flex flex-wrap justify-content-between align-items-start">
                    <div class="logo">
                        <h1 class="mb-0"><a href="index.html" title="Home">
                                <!--<img class="img-fluid"
                                    src="assets/images/logo.png" alt="Logo" srcset="assets/images/retina-logo.png"></a>-->
                        </h1>
                    </div><!-- Logo -->
                    <nav class="d-inline-flex align-items-center">
                        <div class="header-left">
                            <ul class="mb-0 list-unstyled d-inline-flex">
                                <li class="children mb-0 list-unstyled"><a href="index.html#Scope" title="">Scope</a>
                                </li>
                                <li class="menu-item-has-children"><a href="index.html#Topics" title="">Topics</a>
                                </li>
                                <li class="children mb-0 list-unstyled"><a href="index.html#Important_Dates"
                                        title="">Important
                                        Dates</a>
                                </li>
                                <li class="menu-item-has-children"><a href="index.html#Guest_Editors" title="">Guest
                                        Editors</a>
                                </li>
                                <li><a href="index.html#comments" title="">Comments</a></li>
                                <li><a href="index.html#Special_Proposal" title="">Special Issue Proposal</a></li>
                            </ul>
                        </div>

                    </nav>
                </div><!-- Logo Menu Wrap -->
            </div>
        </header><!-- Header -->

        <section>
            <div class="w-100 pt-180 pb-180 page-title-wrap text-center black-layer opc5 position-relative">
                <div class="fixed-bg" style="background-image: url(assets/images/S__320159746.jpg);"></div>
                <div class="container">
                    <div class="page-title-inner d-inline-block">
                        <h1 class="mb-0">Example related publications</h1>
                    </div>
                </div>
            </div><!-- Page Title Wrap -->
        </section>
        <section>
            <div class="w-100 pt-10 pb-120 position-relative">
                <div class="container">
                    <div class="speaker-detail-wrap w-100">
                        <div class="row justify-content-center">
                            <div class="col-md-12 col-sm-12 col-lg-10">
                                <div class="speaker-detail-desc w-100">
                                    <p style="text-align: justify;">
                                    <ol>
                                        <li>S.-Y. Chuang, H.-M. Wang, and Y. Tsao, &quot;Improved Lite Audio-Visual
                                            Speech Enhancement,&quot;<i>IEEE/ACM Transactions on Audio, Speech and
                                                Language Processing,</i>i> vol. 30, pp. 1345-1359, 2022</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>J.-C. Hou, S.-S. Wang, Y.-H. Lai, Y. Tsao, H.-W. Chang, and H.-M. Wang,
                                            &quot;<i>Audio-visual Speech Enhancement using Multimodal Deep Convolutional
                                                Neural Networks,&quot;</i> IEEE Transactions on Emerging Topics in
                                            Computational Intelligence, vol. 2(2), pp. 117-128, 2018. </li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>C. Yu, K.-H. Hung, S.-S. Wang, Y. Tsao, and J.-w. Hung,
                                            &quot;<i>Time-Domain Multi-modal Bone/air Conducted Speech
                                                Enhancement,&quot;</i> IEEE Signal Processing Letters, vol. 27, pp.
                                            1035-1039, 2020.</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>L. A. Passos, J. P. Papa., J. D. Ser. A. Hussain, and A. Adeel,
                                            &quot;Multimodal Audio-visual Information Fusion using
                                            Canonical-correlated Graph Neural Networks for Energy-efficient Speech
                                            Enhancement,&quot;<i> Information Fusion,</i> vol. 90, pp. 1-11, 2023.</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>A. Adeel, M. Gogate, A. Hussain, and W. M. Whitmer, &quot;Lip-reading
                                            Driven Deep Learning Approach for Speech Enhancement,&quot;<i> IEEE
                                                Transactions on Emerging Topics in Computational Intelligence,</i>
                                            vol. 5, no.
                                            3, pp. 481-490, 2021</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>M. Gogate, K. Dashtipour, and A. Hussain, &quot;CochleaNet: A Robust
                                            Language-independent Audio-Visual Model for Speech
                                            Enhancement,&quot;<i> Information Fusion,</i> vol. 63, pp. 273-285, 2020.
                                        </li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>J. Reverdy, S. O&rsquo;Connor Russell, L. Duquenne, D. Garaialde, B. R.
                                            Cowan, and N. Harte. &quot;<i>RoomReader: A Multimodal Corpus of Online
                                                Multiparty Conversational Interactions,&quot;</i> in Proc. ELRA 2022.
                                        </li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>N. Harte and E. Gillen, &quot;TCD-TIMIT: An Audio-Visual Corpus of
                                            Continuous Speech,&quot;<i> IEEE Transactions on Multimedia,</i> vol. 17,
                                            no. 5, pp. 603-615, 2015.</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>T. Afouras, J. S. Chung, A., O. Vinyals, and A. Zisserman, &quot;Deep
                                            Audio-visual Speech Recognition&quot;<i> IEEE Transactions on Pattern
                                                Analysis and Machine Intelligence,</i> vol. 44(12), pp. 8717-8727, 2018.
                                        </li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>Z. Yu, Z. Yin, D. Zhou, D. Wang, F. Wong, and B. Wang, &quot;Talking Head
                                            Generation with Probabilistic Audio-to-visual Diffusion
                                            Priors,&quot;<i> in Proc. CVPR 2022.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>J. Richter, S. Frintrop, and T. Gerkmann. &quot;Audio-visual Speech
                                            Enhancement with Score-Based Generative Models,&quot;<i>
                                                arXiv:2306.01432, 2023.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>Q. Zhu, L. Zhou, Z. Zhang, S. Liu, B. Jiao, J. Zhang, et al.,
                                            &quot;Vatlm: Visual-audio-text Pre-training With Unified Masked
                                            Prediction for Speech Representation Learning,&quot;<i> IEEE
                                                Transactions on Multimedia.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>R. Tan, et al. &quot;Language-Guided Audio-visual Source Separation via
                                            Trimodal Consistency,&quot;<i> in Proc. CVPR 2023.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>I-C. Chen, et al. &quot;Audio-visual Speech Enhancement and Separation by
                                            Utilizing Multi-modal Self-supervised Embeddings,&quot;<i> in Proc.
                                                ICASSPW, 2023.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>J.-C. Chou, C.-M. Chien, and K. Livescu, &quot;AV2Wav: Diffusion-Based
                                            Re-synthesis from Continuous Self-supervised Features for Audio-Visual
                                            Speech Enhancement,&quot;<i> arXiv:2309.08030, 2023.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>Y.-J. Lu, C.-Y. Chang, C. Yu, C.-F. Liu, J.-W. Hung, S. Watanabe, and Y.
                                            Tsao, &quot;Improving Speech Enhancement Performance by Leveraging
                                            Contextual Broad Phonetic Class Information,&quot;<i> IEEE/ACM
                                                Transactions on Audio, Speech, and Language Processing,</i> vol. 31, pp.
                                            2738
                                            &ndash; 2750, 2023.</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>Y. Li, and X. Zhang, &quot;Lip Landmark-based Audio-visual Speech
                                            Enhancement With Multimodal Feature Fusion Network,&quot;<i>
                                                Neurocomputing,</i> vol. 549, 2023.</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>Xu, Haitao, et al. &quot;A Multi-Scale Feature Aggregation Based
                                            Lightweight Network for Audio-Visual Speech Enhancement,&quot;<i> in
                                                Proc. ICASSP 2023.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>M. Chu, Y. Ma, Z. Fan, M. Yang, Z. Tao, and D. Wu, &quot;Gmasegan: A
                                            Global Multi-Head Attention Speech Enhancement Generative Adversarial
                                            Network,&quot;<i> SSRN 4395061.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>L.-C. Chen, et al. &quot;EPG2S: Speech Generation and Speech Enhancement
                                            Based on Electropalatography and Audio Signals using Multimodal
                                            Learning,&quot;<i> IEEE Signal Processing Letters,</i> vol. 29, pp.
                                            2582-2586, 2022.</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>K.-C. Wang, et al. &quot;EMGSE: Acoustic/EMG Fusion for Multimodal Speech
                                            Enhancement,&quot;<i> in Proc. ICASSP 2022.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>J. W. Hwang, J. Park, R. H. Park, and H. M. Park, &quot;Audio-visual
                                            Speech Recognition Based on Joint Training with Audio-visual Speech
                                            Enhancement for Robust Speech Recognition,&quot;<i> Applied Acoustics,</i>
                                            vol. 211, 2023.</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>Z. Zhu, H. Yang, M. Tang, Z. Yang, S. E. Eskimez, and H. Wang,
                                            &quot;Real-Time Audio-Visual End-To-End Speech Enhancement,&quot;<i> in
                                                Proc. ICASSP 2023.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>T. Yoshinaga, K. Tanaka, and S. Morishima, &quot;Audio-Visual Speech
                                            Enhancement with Selective Off-Screen Speech Extraction,&quot;<i>
                                                arXiv:2306.06495.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>C. Valentini-Botinhao, A. L. A. Blanco, O. Klejch, and P. Bell,
                                            &quot;Efficient Intelligibility Evaluation Using Keyword Spotting: A
                                            Study on Audio-Visual Speech Enhancement,&quot;<i> in Proc. ICASSP
                                                2023.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>L. A. Passos, et. al., &quot;Multimodal Speech Enhancement using Burst
                                            Propagation,&quot;<i> arXiv:2209.03275.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>K. Kinoshita, M. Delcroix, A. Ogawa, and T. Nakatani, &quot;Text-informed
                                            Speech Enhancement with Deep Neural Networks,&quot;<i> in Proc.
                                                Interspeech 2015.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>J. Wu et al., &quot;Time Domain Audio Visual Speech Separation,&quot;<i>
                                                in Proc. ASRU 2019.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>R. Gu, S.-X. Zhang, Y. Xu, L. Chen, Y. Zou, and D. Yu, &quot;Multimodal
                                            Multi-channel Target Speech Separation,&quot;<i> IEEE Journal of
                                                Selected Topics in Signal Processing,</i> vol. 14, no. 3, pp. 530-541,
                                            2020.
                                        </li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>Y.-L. Chien, H.-H. Chen, M.-C. Yen, S.-W. Tsai, H.-M. Wang, Y. Tsao, and
                                            T.-S. Chi, &quot;Audio-Visual Mandarin Electrolaryngeal Speech Voice
                                            Conversion,&quot;<i> in Proc. Interspeech 2023.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">
                                        <li>C.-F. Liao, Y. Tsao, X. Lu, and H. Kawai, &quot;Incorporating Symbolic
                                            Sequential Modeling for Speech Enhancement,&quot;<i> in Proc.
                                                Interspeech 2019.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>H. Julien, J. Thomas, Z. V&eacute;ronique, and B. &Eacute;ric,,
                                            &quot;Configurable
                                            EBEN: Extreme Bandwidth Extension Network to Enhance Body-conducted
                                            Speech Capture,&quot;<i> IEEE/ACM Transactions on Audio, Speech, and
                                                Language Processing, in press</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>J. Chen, M. Wang, X. L. Zhang, Z. Huang, and S. Rahardja,
                                            &quot;End-to-end Multi-modal Speech Recognition with Air and Bone
                                            Conducted Speech,<i> in Proc. ICASSP 2022.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>M. Wang, J. Chen, X. Zhang, Z. Huang, and S. Rahardja, &quot;Multi-modal
                                            Speech Enhancement with Bone-conducted Speech in Time Domain,&quot;<i>
                                                Applied Acoustics,</i> vol 200, 2022.</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>H. Wang, X. Zhang, and D. Wang, &quot;Attention-based Fusion for
                                            Bone-conducted and Air-conducted Speech Enhancement in the Complex
                                            Domain,&quot;<i> in Proc. ICASSP 2022.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>H. Wang, X. Zhang, and D. Wang, &quot;Fusing Bone-Conduction and
                                            Air-Conduction Sensors for Complex-Domain Speech Enhancement,&quot;<i>
                                                IEEE/ACM Transactions on Audio, Speech, and Language Processing,</i>
                                            vol. 30, pp. 3134-3143, 2022.</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>Y.-W. Chen, K.-H. Hung, S.-Y. Chuang, J. Sherman, X. Lu, and Y. Tsao,
                                            &quot;A study of Incorporating Articulatory Movement Information in
                                            Speech Enhancement,&quot;<i> in Proc. EUSIPCO 2021.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>A. Ephrat, I. Mosseri, O. Lang, T. Dekel, K. Wilson, A. Hassidim, W. T.
                                            Freeman, and M. Rubinstein. &quot;Looking to Listen at the Cocktail
                                            Party: A
                                            Speaker-independent Audio-visual Model for Speech Separation,&quot;<i>
                                                ACM Transactions on Graphics,</i> vol. 37(4):111, 2018.</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>A. Gabbay, A. Shamir, and S. Peleg, &quot;Visual Speech
                                            Enhancement,&quot;<i> in Proc. Interspeech 2018.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>M. Liuzzolino and K. Koishida. &quot;AV(se)2: Audio-visual Squeeze-excite
                                            Speech Enhancement,&quot;<i> in Proc. ICASSP 2020.</i></li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>D. Michelsanti, Z.-H. Tan, S. Sigurdsson, and J. Jensen.
                                            &quot;Deep-learning-based Audio-visual Speech Enhancement in the Presence
                                            of Lombard Effect,&quot;<i> Speech Communication,</i> vol. 115, pp.
                                            38&ndash;50, 2019.</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>M. Sadeghi, S. Leglaive, X. Alameda-Pineda, L. Girin, and R. Horaud,
                                            &quot;Audio-visual Speech Enhancement using Conditional Variational
                                            Auto-encoders,&quot;<i> IEEE/ACM Transactions on Audio, Speech, and
                                                Language Processing,</i> vol. 28, pp.1788&ndash;1800, 2020.</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>Wu, Jian, et al. &quot;Time domain audio visual speech
                                            separation.&quot;<i> 2019 IEEE automatic speech recognition and
                                                understanding workshop (ASRU).</i> IEEE, 2019.</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">

                                        <li>Tan, Ke, et al. &quot;Audio-visual speech separation and dereverberation
                                            with a two-stage multimodal network.&quot;<i> IEEE Journal of Selected
                                                Topics in Signal Processing </i>14.3 (2020): 542-553.</li>
                                        <hr style="margin-top: 30px; margin-bottom: 30px;">
                                    </ol>
                                </div>
                            </div>
                        </div>
                    </div><!-- Speaker Detail Wrap -->
                </div>
            </div>
        </section>

        <footer>
            <div class="w-100 pt-120 blue-layer opc1 position-relative">
                <div class="fixed-bg back-blend-multiply bg-color4"></div>
                <div class="container position-relative">
                    <div class="clrs-wrap d-flex position-absolute">
                        <i class="bg-color6"></i>
                        <i class="bg-color7"></i>
                        <i class="bg-color8"></i>
                        <i class="bg-color9"></i>
                        <i class="bg-color10"></i>
                        <i class="bg-color11"></i>
                    </div>
                    <p class="mb-0" style="text-align: center; color:white;">JSTSP - &copy; 2024.</p>
                </div>
            </div>
        </footer><!-- Footer -->
    </main><!-- Main Wrapper -->

    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/popper.min.js"></script>
    <script src="assets/js/bootstrap.min.js"></script>
    <script src="assets/js/wow.min.js"></script>
    <script src="assets/js/counterup.min.js"></script>
    <script src="assets/js/jquery.downCount.js"></script>
    <script src="assets/js/jquery.fancybox.min.js"></script>
    <script src="assets/js/perfect-scrollbar.min.js"></script>
    <!--<script src="assets/js/slick.min.js"></script>-->
    <script src="assets/js/custom-scripts.js"></script>
</body>

</html>